{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import norm, pearsonr\n",
    "from scipy.integrate import quad\n",
    "from math import floor, ceil\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skimage.metrics import structural_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "from matplotlib.patches import Circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesee.evaluation import *\n",
    "from bayesee.perception import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.style.use('bayesee.academic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = Path.cwd().parents[0]\n",
    "print(repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = \"PA\"\n",
    "file_name = repo_path / f\"data/search/covert/large-field/p3_data_{subject}.pickle\"\n",
    "\n",
    "with open(file_name, \"rb\") as f:\n",
    "    stimulus, response = pickle.load(f)\n",
    "\n",
    "metadata = stimulus[\"metadata\"]\n",
    "spot_centers = metadata[\"spot_centers\"]\n",
    "monitor_width, monitor_height = metadata[\"monitor_size\"]\n",
    "stimulus_size = metadata[\"stimulus_size\"]\n",
    "n_location = metadata[\"n_location\"]\n",
    "spot_size = metadata[\"spot_size\"]\n",
    "stimulus_ppd = metadata[\"stimulus_ppd\"]\n",
    "target_amplitude = metadata[\"target_amplitude\"]\n",
    "target = metadata[\"target\"]\n",
    "\n",
    "file_name = (\n",
    "    repo_path / f\"data/search/covert/large-field/p2_spatial_statistics_{subject}.csv\"\n",
    ")\n",
    "spatial_statistics_human = pd.read_csv(file_name)\n",
    "local_dp = spatial_statistics_human[\"dp\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_target = stimulus[\"df\"][\"location\"].values\n",
    "human_response = response[\"df\"][\"response_location\"].values\n",
    "human_accuracy = human_target == human_response\n",
    "local_ecc = spatial_statistics_human['ecc'].values\n",
    "array_index_sort = np.insert(np.argsort(local_ecc)+1,0,0)\n",
    "human_confusion = confusion_matrix(human_response, human_target, labels=array_index_sort)\n",
    "human_cr_all = human_confusion[0,0] / sum(human_target==0)\n",
    "human_hit = np.array([human_confusion[l,l] / sum(human_target == array_index_sort[l]) for l in range(1, n_location)])\n",
    "human_fa = human_confusion[1:,0] / sum(human_target==0)\n",
    "human_dp = norm.ppf(human_hit) - norm.ppf(1-human_cr_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_location_ring = np.array([1,1,6,12])\n",
    "\n",
    "def confusion_matrix_ring(confusion_mat, n_location_ring):\n",
    "    # confusion matrix has been sorted by ring\n",
    "    n_ring = len(n_location_ring) - 1\n",
    "    cumsum_ring = np.cumsum(n_location_ring)\n",
    "    \n",
    "    confusion_ring = np.zeros(4*n_ring+1)\n",
    "    confusion_diagonal = confusion_mat.diagonal()\n",
    "    confusion_ring[0] = confusion_diagonal[0]\n",
    "\n",
    "    for index_ring in range(n_ring):\n",
    "        array_index_ring = range(cumsum_ring[index_ring], cumsum_ring[index_ring+1])\n",
    "        hit_ring = confusion_diagonal[array_index_ring].sum()\n",
    "        miss_ring = confusion_mat[0,array_index_ring].sum()\n",
    "        fa_ring = confusion_mat[array_index_ring,0].sum()\n",
    "        fhf_ring = confusion_mat[array_index_ring, 1:].sum() - hit_ring\n",
    "        confusion_ring[1+index_ring*4:5+index_ring*4] = hit_ring, miss_ring, fa_ring, fhf_ring\n",
    "    \n",
    "    return confusion_ring\n",
    "\n",
    "human_confusion_ring = confusion_matrix_ring(human_confusion, n_location_ring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = np.array((0.5, *((0.5 / (n_location - 1),) * (n_location - 1))))\n",
    "assert np.allclose(prior.sum(), 1.0)\n",
    "log_prior_ratio = np.log(prior / prior[0])\n",
    "log_likelihood_ratio = np.zeros_like(prior)\n",
    "model_response = np.zeros_like(human_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bootstrap = 1000\n",
    "array_rmse = np.zeros((n_bootstrap,))\n",
    "array_mae = np.zeros((n_bootstrap,))\n",
    "array_ll = np.zeros((n_bootstrap,))\n",
    "array_pcc = np.zeros((n_bootstrap,))\n",
    "array_ssim = np.zeros((n_bootstrap,))\n",
    "array_cs = np.zeros((n_bootstrap,))\n",
    "array_rmse_ring = np.zeros((n_bootstrap,))\n",
    "array_mae_ring = np.zeros((n_bootstrap,))\n",
    "array_ll_ring = np.zeros((n_bootstrap,))\n",
    "array_pcc_ring = np.zeros((n_bootstrap,))\n",
    "array_ssim_ring = np.zeros((n_bootstrap,))\n",
    "array_cs_ring = np.zeros((n_bootstrap,))\n",
    "array_rmse_diag = np.zeros((n_bootstrap,))\n",
    "array_mae_diag = np.zeros((n_bootstrap,))\n",
    "array_ll_diag = np.zeros((n_bootstrap,))\n",
    "array_pcc_diag = np.zeros((n_bootstrap,))\n",
    "array_ssim_diag = np.zeros((n_bootstrap,))\n",
    "array_cs_diag = np.zeros((n_bootstrap,))\n",
    "array_rmse_dp = np.zeros((n_bootstrap,))\n",
    "array_mae_dp = np.zeros((n_bootstrap,))\n",
    "array_pcc_dp = np.zeros((n_bootstrap,))\n",
    "array_ssim_dp = np.zeros((n_bootstrap,))\n",
    "array_cs_dp = np.zeros((n_bootstrap,))\n",
    "array_rmse_hit = np.zeros((n_bootstrap,))\n",
    "array_mae_hit = np.zeros((n_bootstrap,))\n",
    "array_pcc_hit = np.zeros((n_bootstrap,))\n",
    "array_ssim_hit = np.zeros((n_bootstrap,))\n",
    "array_cs_hit = np.zeros((n_bootstrap,))\n",
    "array_rmse_fa = np.zeros((n_bootstrap,))\n",
    "array_mae_fa = np.zeros((n_bootstrap,))\n",
    "array_pcc_fa = np.zeros((n_bootstrap,))\n",
    "array_ssim_fa = np.zeros((n_bootstrap,))\n",
    "array_cs_fa = np.zeros((n_bootstrap,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_bootstrap in range(n_bootstrap):\n",
    "    for index_trial in range(len(human_target)):\n",
    "        array_standard_normal = np.random.normal(size=(n_location - 1,))\n",
    "        log_likelihood_ratio[1:] = local_dp * (\n",
    "            array_standard_normal - local_dp / 2\n",
    "        )\n",
    "\n",
    "        if human_target[index_trial] > 0:\n",
    "            log_likelihood_ratio[human_target[index_trial]] +=  local_dp[human_target[index_trial] - 1]**2\n",
    "\n",
    "        log_posterior_ratio = log_prior_ratio + log_likelihood_ratio\n",
    "        model_response[index_trial] = np.argmax(log_posterior_ratio)\n",
    "        \n",
    "    model_confusion = confusion_matrix(model_response, human_target, labels=array_index_sort)\n",
    "    model_confusion_probability = (model_confusion + 1) # Laplace smoothing\n",
    "    model_confusion_probability = model_confusion_probability / model_confusion_probability.sum()\n",
    "    \n",
    "    model_confusion_ring = confusion_matrix_ring(model_confusion, n_location_ring)\n",
    "    model_confusion_ring_probability = (model_confusion_ring + 1) # Laplace smoothing\n",
    "    model_confusion_ring_probability = model_confusion_ring_probability / model_confusion_ring_probability.sum()\n",
    "\n",
    "    model_cr_all = model_confusion[0,0] / sum(human_target==0)\n",
    "    model_hit = np.array([model_confusion[l,l] / sum(human_target == array_index_sort[l]) for l in range(1, n_location)])\n",
    "    model_fa = model_confusion[1:,0] / sum(human_target==0)\n",
    "    model_dp = norm.ppf(model_hit) - norm.ppf(1-model_cr_all)\n",
    "\n",
    "    array_rmse[index_bootstrap] = rmse(human_confusion, model_confusion)\n",
    "    array_mae[index_bootstrap] = mae(human_confusion, model_confusion)\n",
    "    array_ll[index_bootstrap] = (human_confusion * np.log(model_confusion_probability)).sum()\n",
    "    array_pcc[index_bootstrap] = pearson(human_confusion, model_confusion)\n",
    "    array_ssim[index_bootstrap] = ssim(human_confusion, model_confusion)\n",
    "    array_cs[index_bootstrap] = cosine_similarity(human_confusion, model_confusion)\n",
    "    \n",
    "    array_rmse_ring[index_bootstrap] = rmse(human_confusion_ring, model_confusion_ring)\n",
    "    array_mae_ring[index_bootstrap] = mae(human_confusion_ring, model_confusion_ring)\n",
    "    array_ll_ring[index_bootstrap] = (human_confusion_ring * np.log(model_confusion_ring_probability)).sum()\n",
    "    array_pcc_ring[index_bootstrap] = pearson(human_confusion_ring, model_confusion_ring)\n",
    "    array_ssim_ring[index_bootstrap] = ssim(human_confusion_ring, model_confusion_ring)\n",
    "    array_cs_ring[index_bootstrap] = cosine_similarity(human_confusion_ring, model_confusion_ring)\n",
    "    \n",
    "    array_rmse_diag[index_bootstrap] = rmse(human_confusion.diagonal(), model_confusion.diagonal())\n",
    "    array_mae_diag[index_bootstrap] = mae(human_confusion.diagonal(), model_confusion.diagonal())\n",
    "    array_ll_diag[index_bootstrap] = (human_confusion.diagonal() * np.log(model_confusion_probability.diagonal())).sum()\n",
    "    array_pcc_diag[index_bootstrap] = pearson(human_confusion.diagonal(), model_confusion.diagonal())\n",
    "    array_ssim_diag[index_bootstrap] = ssim(human_confusion.diagonal(), model_confusion.diagonal())\n",
    "    array_cs_diag[index_bootstrap] = cosine_similarity(human_confusion.diagonal(), model_confusion.diagonal())\n",
    "    \n",
    "    array_rmse_dp[index_bootstrap] = rmse(human_dp, model_dp)\n",
    "    array_mae_dp[index_bootstrap] = mae(human_dp, model_dp)\n",
    "    array_pcc_dp[index_bootstrap] = pearson(human_dp, model_dp)\n",
    "    array_ssim_dp[index_bootstrap] = ssim(human_dp, model_dp)\n",
    "    array_cs_dp[index_bootstrap] = cosine_similarity(human_dp, model_dp)\n",
    "    \n",
    "    array_rmse_hit[index_bootstrap] = rmse(human_hit, model_hit)\n",
    "    array_mae_hit[index_bootstrap] = mae(human_hit, model_hit)\n",
    "    array_pcc_hit[index_bootstrap] = pearson(human_hit, model_hit)\n",
    "    array_ssim_hit[index_bootstrap] = ssim(human_hit, model_hit)\n",
    "    array_cs_hit[index_bootstrap] = cosine_similarity(human_hit, model_hit)\n",
    "    \n",
    "    array_rmse_fa[index_bootstrap] = rmse(human_fa, model_fa)\n",
    "    array_mae_fa[index_bootstrap] = mae(human_fa, model_fa)\n",
    "    array_pcc_fa[index_bootstrap] = pearson(human_fa, model_fa)\n",
    "    array_ssim_fa[index_bootstrap] = ssim(human_fa, model_fa)\n",
    "    array_cs_fa[index_bootstrap] = cosine_similarity(human_fa, model_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"\"\"\n",
    "| Cost | Mean | SD | 2.5th | 97.5th |\n",
    "| :---: | :---: | :---: | :---: | :---: |\n",
    "| Root Mean Squared Error (RMSE) | {array_rmse.mean():.3f} | {array_rmse.std():.3f} | {np.percentile(array_rmse, 2.5):.3f} | {np.percentile(array_rmse, 97.5):.3f} |\n",
    "| Mean Absolute Error (MAE) | {array_mae.mean():.3f} | {array_mae.std():.3f} | {np.percentile(array_mae, 2.5):.3f} | {np.percentile(array_mae, 97.5):.3f} |\n",
    "| Log Likelihood (LL) | {array_ll.mean():.3f} | {array_ll.std():.3f} | {np.percentile(array_ll, 2.5):.3f} | {np.percentile(array_ll, 97.5):.3f} |\n",
    "| Pearson Correlation Coefficient (PCC) | {array_pcc.mean():.3f} | {array_pcc.std():.3f} | {np.percentile(array_pcc, 2.5):.3f} | {np.percentile(array_pcc, 97.5):.3f} |\n",
    "| Structural Similarity Index Measure (SSIM) | {array_ssim.mean():.3f} | {array_ssim.std():.3f} | {np.percentile(array_ssim, 2.5):.3f} | {np.percentile(array_ssim, 97.5):.3f} |\n",
    "| Cosine Similarity (CS) | {array_cs.mean():.3f} | {array_cs.std():.3f} | {np.percentile(array_cs, 2.5):.3f} | {np.percentile(array_cs, 97.5):.3f} |\n",
    "| Ring Root Mean Squared Error (RMSE) | {array_rmse_ring.mean():.3f} | {array_rmse_ring.std():.3f} | {np.percentile(array_rmse_ring, 2.5):.3f} | {np.percentile(array_rmse_ring, 97.5):.3f} |\n",
    "| Ring Mean Absolute Error (MAE) | {array_mae_ring.mean():.3f} | {array_mae_ring.std():.3f} | {np.percentile(array_mae_ring, 2.5):.3f} | {np.percentile(array_mae_ring, 97.5):.3f} |\n",
    "| Ring Log Likelihood (LL) | {array_ll_ring.mean():.3f} | {array_ll_ring.std():.3f} | {np.percentile(array_ll_ring, 2.5):.3f} | {np.percentile(array_ll_ring, 97.5):.3f} |\n",
    "| Ring Pearson Correlation Coefficient (PCC) | {array_pcc_ring.mean():.3f} | {array_pcc_ring.std():.3f} | {np.percentile(array_pcc_ring, 2.5):.3f} | {np.percentile(array_pcc_ring, 97.5):.3f} |\n",
    "| Ring Structural Similarity Index Measure (SSIM) | {array_ssim_ring.mean():.3f} | {array_ssim_ring.std():.3f} | {np.percentile(array_ssim_ring, 2.5):.3f} | {np.percentile(array_ssim_ring, 97.5):.3f} |\n",
    "| Ring Cosine Similarity (CS) | {array_cs_ring.mean():.3f} | {array_cs_ring.std():.3f} | {np.percentile(array_cs_ring, 2.5):.3f} | {np.percentile(array_cs_ring, 97.5):.3f} |\n",
    "| Diagonal Root Mean Squared Error (RMSE) | {array_rmse_diag.mean():.3f} | {array_rmse_diag.std():.3f} | {np.percentile(array_rmse_diag, 2.5):.3f} | {np.percentile(array_rmse_diag, 97.5):.3f} |\n",
    "| Diagonal Mean Absolute Error (MAE) | {array_mae_diag.mean():.3f} | {array_mae_diag.std():.3f} | {np.percentile(array_mae_diag, 2.5):.3f} | {np.percentile(array_mae_diag, 97.5):.3f} |\n",
    "| Diagonal Log Likelihood (LL) | {array_ll_diag.mean():.3f} | {array_ll_diag.std():.3f} | {np.percentile(array_ll_diag, 2.5):.3f} | {np.percentile(array_ll_diag, 97.5):.3f} |\n",
    "| Diagonal Pearson Correlation Coefficient (PCC) | {array_pcc_diag.mean():.3f} | {array_pcc_diag.std():.3f} | {np.percentile(array_pcc_diag, 2.5):.3f} | {np.percentile(array_pcc_diag, 97.5):.3f} |\n",
    "| Diagonal Structural Similarity Index Measure (SSIM) | {array_ssim_diag.mean():.3f} | {array_ssim_diag.std():.3f} | {np.percentile(array_ssim_diag, 2.5):.3f} | {np.percentile(array_ssim_diag, 97.5):.3f} |\n",
    "| Diagonal Cosine Similarity (CS) | {array_cs_diag.mean():.3f} | {array_cs_diag.std():.3f} | {np.percentile(array_cs_diag, 2.5):.3f} | {np.percentile(array_cs_diag, 97.5):.3f} |\n",
    "| D' Root Mean Squared Error (RMSE) | {array_rmse_dp.mean():.3f} | {array_rmse_dp.std():.3f} | {np.percentile(array_rmse_dp, 2.5):.3f} | {np.percentile(array_rmse_dp, 97.5):.3f} |\n",
    "| D' Mean Absolute Error (MAE) | {array_mae_dp.mean():.3f} | {array_mae_dp.std():.3f} | {np.percentile(array_mae_dp, 2.5):.3f} | {np.percentile(array_mae_dp, 97.5):.3f} |\n",
    "| D' Pearson Correlation Coefficient (PCC) | {array_pcc_dp.mean():.3f} | {array_pcc_dp.std():.3f} | {np.percentile(array_pcc_dp, 2.5):.3f} | {np.percentile(array_pcc_dp, 97.5):.3f} |\n",
    "| D' Structural Similarity Index Measure (SSIM) | {array_ssim_dp.mean():.3f} | {array_ssim_dp.std():.3f} | {np.percentile(array_ssim_dp, 2.5):.3f} | {np.percentile(array_ssim_dp, 97.5):.3f} |\n",
    "| D' Cosine Similarity (CS) | {array_cs_dp.mean():.3f} | {array_cs_dp.std():.3f} | {np.percentile(array_cs_dp, 2.5):.3f} | {np.percentile(array_cs_dp, 97.5):.3f} |\n",
    "| Hit Root Mean Squared Error (RMSE) | {array_rmse_hit.mean():.3f} | {array_rmse_hit.std():.3f} | {np.percentile(array_rmse_hit, 2.5):.3f} | {np.percentile(array_rmse_hit, 97.5):.3f} |\n",
    "| Hit Mean Absolute Error (MAE) | {array_mae_hit.mean():.3f} | {array_mae_hit.std():.3f} | {np.percentile(array_mae_hit, 2.5):.3f} | {np.percentile(array_mae_hit, 97.5):.3f} |\n",
    "| Hit Pearson Correlation Coefficient (PCC) | {array_pcc_hit.mean():.3f} | {array_pcc_hit.std():.3f} | {np.percentile(array_pcc_hit, 2.5):.3f} | {np.percentile(array_pcc_hit, 97.5):.3f} |\n",
    "| Hit Structural Similarity Index Measure (SSIM) | {array_ssim_hit.mean():.3f} | {array_ssim_hit.std():.3f} | {np.percentile(array_ssim_hit, 2.5):.3f} | {np.percentile(array_ssim_hit, 97.5):.3f} |\n",
    "| Hit Cosine Similarity (CS) | {array_cs_hit.mean():.3f} | {array_cs_hit.std():.3f} | {np.percentile(array_cs_hit, 2.5):.3f} | {np.percentile(array_cs_hit, 97.5):.3f} |\n",
    "| False Alarm Root Mean Squared Error (RMSE) | {array_rmse_fa.mean():.3f} | {array_rmse_fa.std():.3f} | {np.percentile(array_rmse_fa, 2.5):.3f} | {np.percentile(array_rmse_fa, 97.5):.3f} |\n",
    "| False Alarm Mean Absolute Error (MAE) | {array_mae_fa.mean():.3f} | {array_mae_fa.std():.3f} | {np.percentile(array_mae_fa, 2.5):.3f} | {np.percentile(array_mae_fa, 97.5):.3f} |\n",
    "| False Alarm Pearson Correlation Coefficient (PCC) | {array_pcc_fa.mean():.3f} | {array_pcc_fa.std():.3f} | {np.percentile(array_pcc_fa, 2.5):.3f} | {np.percentile(array_pcc_fa, 97.5):.3f} |\n",
    "| False Alarm Structural Similarity Index Measure (SSIM) | {array_ssim_fa.mean():.3f} | {array_ssim_fa.std():.3f} | {np.percentile(array_ssim_fa, 2.5):.3f} | {np.percentile(array_ssim_fa, 97.5):.3f} |\n",
    "| False Alarm Cosine Similarity (CS) | {array_cs_fa.mean():.3f} | {array_cs_fa.std():.3f} | {np.percentile(array_cs_fa, 2.5):.3f} | {np.percentile(array_cs_fa, 97.5):.3f} |\n",
    "\n",
    "(Bootstrapped {n_bootstrap} times.)\n",
    "\"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
